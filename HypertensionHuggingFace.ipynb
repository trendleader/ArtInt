{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPxUrLBS0RbrCo5iZYx+gsF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trendleader/ArtInt/blob/main/HypertensionHuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQlZlDtk_RuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg77Ocs49eDS"
      },
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "dwbsaAp7_Uaq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ19TQe5KkQH"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "ZJJ2EiPQpCMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Can you provide a brief explanation of hypertension including its symptoms, cause and common treatments?\"}\n",
        "]\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    max_tokens=150,\n",
        "    temperature=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "01Iqvpr7pvWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1345c1e"
      },
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "or_E-JGl_KJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Response from GPT-4 Turbo:\")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEExLCj8q8yo",
        "outputId": "2ebd2663-37a8-4279-886b-667dcc78c2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from GPT-4 Turbo:\n",
            "Hypertension, also known as high blood pressure, is a condition in which the force of blood against the walls of the arteries is consistently too high. This can lead to serious health complications such as heart disease, stroke, and kidney failure.\n",
            "\n",
            "Symptoms of hypertension may include headaches, shortness of breath, dizziness, chest pain, and vision problems. However, many people with hypertension do not experience any symptoms, which is why it is often referred to as a \"silent killer.\"\n",
            "\n",
            "The exact cause of hypertension is often unknown, but risk factors include genetics, age, obesity, lack of physical activity, excessive salt intake, and chronic stress.\n",
            "\n",
            "Common treatments for hypertension include lifestyle changes such as maintaining a healthy diet, exercising regularly, reducing stress\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a44c115"
      },
      "source": [
        "# Task\n",
        "Generate Python code to use a Hugging Face model for text generation in Google Colab, replacing the use of OpenAI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adbaf8c0"
      },
      "source": [
        "## Install libraries\n",
        "\n",
        "### Subtask:\n",
        "Install the `transformers` and `accelerate` libraries from Hugging Face.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "115fb25b"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the necessary libraries for using Hugging Face models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3863c14",
        "outputId": "924f9688-46b0-4f7e-ac4f-73cc3ec8f07f"
      },
      "source": [
        "!pip install transformers accelerate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ccc37d"
      },
      "source": [
        "## Load the model and tokenizer\n",
        "\n",
        "### Subtask:\n",
        "Load a pre-trained model and tokenizer from the Hugging Face Hub.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13fb07da"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary classes and load the pre-trained model and tokenizer from Hugging Face.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1a3cfaa"
      },
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9530cff2"
      },
      "source": [
        "## Generate text\n",
        "\n",
        "### Subtask:\n",
        "Use the loaded model and tokenizer to generate text based on a prompt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3293a33"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the loaded model and tokenizer to generate text based on a prompt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c3d25a2",
        "outputId": "c590c3a4-4c5d-4852-eb99-defef5ac1e7f"
      },
      "source": [
        "prompt = \"Hypertension is a medical condition characterized by\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "generated_output = model.generate(input_ids, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "generated_text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
        "print(\"Generated text:\")\n",
        "print(generated_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "Hypertension is a medical condition characterized by a high blood pressure, high cholesterol, and high blood pressure. It is caused by a buildup of cholesterol in the blood. It can be caused by:\n",
            "\n",
            "High blood pressure\n",
            "\n",
            "High cholesterol\n",
            "\n",
            "High cholesterol buildup\n",
            "\n",
            "High blood pressure\n",
            "\n",
            "High cholesterol buildup\n",
            "\n",
            "High blood pressure buildup\n",
            "\n",
            "High blood pressure buildup\n",
            "\n",
            "High blood pressure buildup\n",
            "\n",
            "High blood pressure buildup\n",
            "\n",
            "High blood pressure buildup\n",
            "\n",
            "High blood pressure buildup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44f34f71"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The necessary `transformers` and `accelerate` libraries were already installed in the environment.\n",
        "*   The \"gpt2\" model and its corresponding tokenizer were successfully loaded from the Hugging Face Hub.\n",
        "*   Text was successfully generated based on the provided prompt using the loaded model and tokenizer.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The setup is ready for experimenting with different prompts and text generation parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ca9634"
      },
      "source": [
        "## Connect to a different Hugging Face Model (e.g., Mistral)\n",
        "\n",
        "### Subtask:\n",
        "Modify the code to load a different model and tokenizer from the Hugging Face Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "320c126e"
      },
      "source": [
        "**Reasoning**:\n",
        "Change the `model_name` to the desired Hugging Face model and reload the tokenizer and model. If the model requires authentication (like Llama or some Mistral versions), you'll need to add code to log in to Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d4ffff0"
      },
      "source": [
        "# If the model requires authentication, uncomment and run this cell\n",
        "# from huggingface_hub import login\n",
        "# from google.colab import userdata\n",
        "#\n",
        "# # Get your Hugging Face token from Colab secrets\n",
        "# hf_token = userdata.get('HF_TOKEN')\n",
        "#\n",
        "# # Log in to Hugging Face\n",
        "# login(token=hf_token)\n",
        "\n",
        "# Specify the new model name\n",
        "model_name = \"mistralai/Mistral-7B-v0.1\" # Example publicly available Mistral model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "print(f\"Successfully loaded model: {model_name}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9333aae"
      },
      "source": [
        "## Generate text with the new model\n",
        "\n",
        "### Subtask:\n",
        "Use the newly loaded model and tokenizer to generate text based on a prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0e9bdf0"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the loaded model and tokenizer to generate text based on a prompt, similar to before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1be90dc"
      },
      "source": [
        "prompt = \"Can you provide a brief explanation of hypertension including its symptoms, cause and common treatments?\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text (adjust parameters as needed for the new model)\n",
        "# You might need to experiment with generation parameters for optimal results with different models.\n",
        "generated_output = model.generate(input_ids, max_length=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "generated_text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Generated text:\")\n",
        "print(generated_text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}